{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88c32460",
   "metadata": {},
   "source": [
    "# Parquet vs. Vortex vs. Lance performance\n",
    "\n",
    "Generate a wide random dataset (~100k rows x 4k float columns + 50 string columns) and benchmark on-disk formats.\n",
    "\n",
    "Requires `pyarrow`, `lancedb`, `vortex-data`, `duckdb` (installed via uv).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966bf932",
   "metadata": {},
   "source": [
    "**Setup**\n",
    "- Run `uv run poe lab` (or `uv venv && uv sync && uv run jupyter lab`).\n",
    "- Artifacts are written under `data/` (git-ignored).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d042afca",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import shutil\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.dataset as ds\n",
    "import lancedb\n",
    "import duckdb\n",
    "import vortex\n",
    "import vortex.io as vxio\n",
    "\n",
    "pd.set_option(\"display.precision\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56a7518f",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 4000, 50, numpy.float64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = Path(\"data\")\n",
    "shutil.rmtree(DATA_DIR, ignore_errors=True)\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "N_ROWS = 100_000\n",
    "N_COLS = 4_000  # float columns\n",
    "STR_COLS = 50\n",
    "DTYPE = np.float64\n",
    "REPEATS = 5\n",
    "RANDOM_READ_REPEATS = REPEATS\n",
    "RANDOM_ROW_COUNT = 10\n",
    "SEED = 13\n",
    "\n",
    "RUN_DUCKDB = True\n",
    "DUCK_ROWS = None  # use full table\n",
    "DUCK_REPEATS = REPEATS\n",
    "\n",
    "PARQUET_PATH = DATA_DIR / \"wide.parquet\"\n",
    "PARQUET_DUCK_PATH = DATA_DIR / \"wide_duck.parquet\"\n",
    "LANCE_PATH = DATA_DIR / \"lance_db\"\n",
    "VORTEX_PATH = DATA_DIR / \"wide.vortex\"\n",
    "DUCK_PATH = DATA_DIR / \"wide.duckdb\"\n",
    "LANCE_TABLE = \"bench\"\n",
    "DUCK_TABLE = \"bench\"\n",
    "\n",
    "# Resolve versions\n",
    "try:\n",
    "    import importlib.metadata as importlib_metadata\n",
    "except ImportError:\n",
    "    import importlib_metadata\n",
    "\n",
    "try:\n",
    "    vortex_version = getattr(vortex, '__version__', None) or importlib_metadata.version('vortex-data')\n",
    "except importlib_metadata.PackageNotFoundError:\n",
    "    try:\n",
    "        vortex_version = importlib_metadata.version('vortex')\n",
    "    except importlib_metadata.PackageNotFoundError:\n",
    "        vortex_version = 'unknown'\n",
    "\n",
    "VERSIONS = {\n",
    "    'pyarrow': pa.__version__,\n",
    "    'lancedb': getattr(lancedb, '__version__', 'unknown'),\n",
    "    'duckdb': duckdb.__version__,\n",
    "    'vortex': vortex_version,\n",
    "}\n",
    "FORMAT_VERSIONS = {\n",
    "    'Parquet (pyarrow, zstd)': f\"pyarrow {VERSIONS['pyarrow']}\",\n",
    "    'Parquet (duckdb, zstd)': f\"duckdb {VERSIONS['duckdb']}\",\n",
    "    'Lance (lancedb)': f\"lancedb {VERSIONS['lancedb']}\",\n",
    "    'Vortex': f\"vortex {VERSIONS['vortex']}\",\n",
    "    'DuckDB (file table)': f\"duckdb {VERSIONS['duckdb']}\",\n",
    "}\n",
    "\n",
    "N_ROWS, N_COLS, STR_COLS, DTYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c019e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table rows: 100000 cols: 4051\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(SEED)\n",
    "# Add an explicit row id column so we can filter for random access reads later.\n",
    "row_ids = pa.array(np.arange(N_ROWS, dtype=np.int64))\n",
    "float_names = [f\"col_{i:04d}\" for i in range(N_COLS)]\n",
    "float_columns = [pa.array(rng.standard_normal(N_ROWS, dtype=DTYPE)) for _ in range(N_COLS)]\n",
    "\n",
    "str_names = [f\"str_{i:04d}\" for i in range(STR_COLS)]\n",
    "str_columns = []\n",
    "for _ in range(STR_COLS):\n",
    "    ints = rng.integers(0, 1_000_000, size=N_ROWS, dtype=np.int32)\n",
    "    strings = np.char.add('s', ints.astype(str))\n",
    "    str_columns.append(pa.array(strings))\n",
    "\n",
    "column_names = float_names + str_names\n",
    "columns = [row_ids] + float_columns + str_columns\n",
    "column_names = ['row_id'] + column_names\n",
    "table = pa.Table.from_arrays(columns, names=column_names)\n",
    "print('table rows:', table.num_rows, 'cols:', table.num_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bec571c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "duck_table = table\n",
    "RANDOM_INDICES = sorted(rng.choice(table.num_rows, size=RANDOM_ROW_COUNT, replace=False).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "599bc649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_path(path: Path) -> None:\n",
    "    if path.is_dir():\n",
    "        shutil.rmtree(path, ignore_errors=True)\n",
    "    elif path.exists():\n",
    "        path.unlink()\n",
    "\n",
    "\n",
    "def path_size_bytes(path: Path) -> int:\n",
    "    if path.is_file():\n",
    "        return path.stat().st_size\n",
    "    if path.is_dir():\n",
    "        return sum(p.stat().st_size for p in path.rglob('*') if p.is_file())\n",
    "    return 0\n",
    "\n",
    "\n",
    "def run_benchmarks(table: pa.Table, configs, repeats: int = 3):\n",
    "    results = []\n",
    "    for cfg in configs:\n",
    "        cfg_repeats = cfg.get('repeats', repeats)\n",
    "        cfg_random_repeats = cfg.get('random_repeats', cfg_repeats)\n",
    "        write_times = []\n",
    "        read_times = []\n",
    "        random_read_times = []\n",
    "        print(f\"[format start] {cfg['name']}\", flush=True)\n",
    "        for run_idx in range(cfg_repeats):\n",
    "            if cfg.get('cleanup', True):\n",
    "                drop_path(cfg['path'])\n",
    "            t0 = time.perf_counter()\n",
    "            cfg_table = cfg.get('table', table)\n",
    "            cfg['write'](cfg_table, cfg['path'])\n",
    "            elapsed = time.perf_counter() - t0\n",
    "            write_times.append(elapsed)\n",
    "            print(f\"[write] {cfg['name']} run {run_idx + 1}/{cfg_repeats}: {elapsed:.2f}s\", flush=True)\n",
    "\n",
    "        size_bytes = path_size_bytes(cfg['path'])\n",
    "\n",
    "        for run_idx in range(cfg_repeats):\n",
    "            gc.collect()\n",
    "            t0 = time.perf_counter()\n",
    "            _ = cfg['read'](cfg['path'])\n",
    "            elapsed = time.perf_counter() - t0\n",
    "            read_times.append(elapsed)\n",
    "            print(f\"[read ] {cfg['name']} run {run_idx + 1}/{cfg_repeats}: {elapsed:.2f}s\", flush=True)\n",
    "\n",
    "        for run_idx in range(cfg_random_repeats):\n",
    "            gc.collect()\n",
    "            t0 = time.perf_counter()\n",
    "            random_fn = cfg.get('random_read')\n",
    "            if random_fn is None:\n",
    "                tbl = cfg['read'](cfg['path'])\n",
    "                _ = tbl.take(RANDOM_INDICES)\n",
    "            else:\n",
    "                _ = random_fn(cfg['path'], indices=RANDOM_INDICES)\n",
    "            elapsed = time.perf_counter() - t0\n",
    "            random_read_times.append(elapsed)\n",
    "            print(f\"[rnd  ] {cfg['name']} run {run_idx + 1}/{cfg_random_repeats}: {elapsed:.2f}s\", flush=True)\n",
    "\n",
    "        results.append({\n",
    "            'format': cfg['name'],\n",
    "            'write_seconds': write_times,\n",
    "            'read_seconds': read_times,\n",
    "            'random_read_seconds': random_read_times,\n",
    "            'size_mb': size_bytes / (1024 * 1024),\n",
    "        })\n",
    "        print(f\"[format end] {cfg['name']}\", flush=True)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "425ec6bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_path(LANCE_PATH)\n",
    "LANCE_DB = lancedb.connect(LANCE_PATH)\n",
    "\n",
    "def reset_lance_table(db, table_name):\n",
    "    try:\n",
    "        if hasattr(db, 'table_names') and table_name in db.table_names():\n",
    "            if hasattr(db, 'drop_table'):\n",
    "                db.drop_table(table_name)\n",
    "            else:\n",
    "                drop_path(LANCE_PATH)\n",
    "                return lancedb.connect(LANCE_PATH)\n",
    "    except Exception:\n",
    "        drop_path(LANCE_PATH)\n",
    "        return lancedb.connect(LANCE_PATH)\n",
    "    return db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd16a240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formats: ['Parquet (pyarrow, zstd)', 'Parquet (duckdb, zstd)', 'Lance (lancedb)', 'Vortex', 'DuckDB (file table)']\n"
     ]
    }
   ],
   "source": [
    "def lance_write(tbl, path=LANCE_PATH, table_name=LANCE_TABLE):\n",
    "    global LANCE_DB\n",
    "    LANCE_DB = reset_lance_table(LANCE_DB, table_name)\n",
    "    LANCE_DB.create_table(table_name, tbl, mode=\"overwrite\")\n",
    "\n",
    "\n",
    "def lance_read(path=LANCE_PATH, table_name=LANCE_TABLE):\n",
    "    return LANCE_DB.open_table(table_name).to_arrow()\n",
    "\n",
    "\n",
    "def vortex_write(tbl, path=VORTEX_PATH):\n",
    "    drop_path(path)\n",
    "    vxio.write(tbl, str(path))\n",
    "\n",
    "\n",
    "def vortex_read(path=VORTEX_PATH):\n",
    "    return vortex.open(str(path)).to_arrow().read_all()\n",
    "\n",
    "\n",
    "def duck_write(tbl, path=DUCK_PATH, table_name=DUCK_TABLE):\n",
    "    drop_path(path)\n",
    "    con = duckdb.connect(str(path))\n",
    "    con.register('tmp_tbl', tbl)\n",
    "    con.execute(f\"CREATE TABLE {table_name} AS SELECT * FROM tmp_tbl\")\n",
    "    con.close()\n",
    "\n",
    "\n",
    "def duck_read(path=DUCK_PATH, table_name=DUCK_TABLE):\n",
    "    with duckdb.connect(str(path)) as con:\n",
    "        return con.execute(f\"SELECT * FROM {table_name}\").fetch_arrow_table()\n",
    "\n",
    "\n",
    "def parquet_duck_write(tbl, path=PARQUET_DUCK_PATH):\n",
    "    drop_path(path)\n",
    "    con = duckdb.connect()\n",
    "    con.register('tmp_tbl', tbl)\n",
    "    con.execute(f\"COPY (SELECT * FROM tmp_tbl) TO '{path}' WITH (FORMAT 'PARQUET', COMPRESSION 'ZSTD')\")\n",
    "    con.close()\n",
    "\n",
    "\n",
    "def parquet_duck_read(path=PARQUET_DUCK_PATH):\n",
    "    with duckdb.connect() as con:\n",
    "        return con.execute(f\"SELECT * FROM read_parquet('{path}')\").fetch_arrow_table()\n",
    "\n",
    "\n",
    "def parquet_random_read(path=PARQUET_PATH, indices=None):\n",
    "    try:\n",
    "        dataset = ds.dataset(path, format=\"parquet\")\n",
    "        filt = ds.field('row_id').isin(pa.array(indices, type=pa.int64()))\n",
    "        return dataset.to_table(filter=filt)\n",
    "    except Exception:\n",
    "        return pq.read_table(path).take(indices)\n",
    "\n",
    "\n",
    "def parquet_duck_random_read(path=PARQUET_DUCK_PATH, indices=None):\n",
    "    idx_list = \",\".join(str(int(i)) for i in indices)\n",
    "    with duckdb.connect() as con:\n",
    "        return con.execute(f\"SELECT * FROM read_parquet('{path}') WHERE row_id IN ({idx_list})\").fetch_arrow_table()\n",
    "\n",
    "\n",
    "def lance_random_read(path=LANCE_PATH, table_name=LANCE_TABLE, indices=None):\n",
    "    idx_list = \",\".join(str(int(i)) for i in indices)\n",
    "    table = LANCE_DB.open_table(table_name)\n",
    "    try:\n",
    "        return table.query().where(f\"row_id IN ({idx_list})\").to_arrow()\n",
    "    except Exception:\n",
    "        return table.to_arrow().take(indices)\n",
    "\n",
    "\n",
    "def vortex_random_read(path=VORTEX_PATH, indices=None):\n",
    "    reader = vortex.open(str(path)).to_arrow()\n",
    "    target = sorted(int(i) for i in indices)\n",
    "    collected = None\n",
    "    offset = 0\n",
    "    for batch in reader:\n",
    "        batch_len = batch.num_rows\n",
    "        batch_matches = [idx - offset for idx in target if offset <= idx < offset + batch_len]\n",
    "        if not batch_matches:\n",
    "            offset += batch_len\n",
    "            continue\n",
    "        if collected is None:\n",
    "            collected = {name: [] for name in batch.schema.names}\n",
    "        for name, column in zip(batch.schema.names, batch.columns):\n",
    "            for rel_idx in batch_matches:\n",
    "                collected[name].append(column[rel_idx].as_py())\n",
    "        offset += batch_len\n",
    "        if len(next(iter(collected.values()))) >= len(target):\n",
    "            break\n",
    "    if not collected:\n",
    "        return pa.Table.from_arrays([], names=[])\n",
    "    arrays = [pa.array(collected[name]) for name in collected.keys()]\n",
    "    return pa.Table.from_arrays(arrays, names=list(collected.keys()))\n",
    "\n",
    "\n",
    "def duck_random_read(path=DUCK_PATH, table_name=DUCK_TABLE, indices=None):\n",
    "    idx_list = \",\".join(str(int(i)) for i in indices)\n",
    "    with duckdb.connect(str(path)) as con:\n",
    "        return con.execute(f\"SELECT * FROM {table_name} WHERE row_id IN ({idx_list})\").fetch_arrow_table()\n",
    "\n",
    "\n",
    "format_configs = [\n",
    "    {\n",
    "        'name': 'Parquet (pyarrow, zstd)',\n",
    "        'path': PARQUET_PATH,\n",
    "        'write': lambda tbl, path=PARQUET_PATH: pq.write_table(tbl, path, compression='zstd'),\n",
    "        'read': lambda path=PARQUET_PATH: pq.read_table(path),\n",
    "        'random_read': parquet_random_read,\n",
    "        'random_repeats': RANDOM_READ_REPEATS,\n",
    "    },\n",
    "    {\n",
    "        'name': 'Parquet (duckdb, zstd)',\n",
    "        'path': PARQUET_DUCK_PATH,\n",
    "        'write': parquet_duck_write,\n",
    "        'read': parquet_duck_read,\n",
    "        'random_read': parquet_duck_random_read,\n",
    "        'random_repeats': RANDOM_READ_REPEATS,\n",
    "    },\n",
    "    {\n",
    "        'name': 'Lance (lancedb)',\n",
    "        'path': LANCE_PATH,\n",
    "        'write': lance_write,\n",
    "        'read': lance_read,\n",
    "        'cleanup': False,\n",
    "        'random_read': lance_random_read,\n",
    "        'random_repeats': RANDOM_READ_REPEATS,\n",
    "    },\n",
    "    {\n",
    "        'name': 'Vortex',\n",
    "        'path': VORTEX_PATH,\n",
    "        'write': vortex_write,\n",
    "        'read': vortex_read,\n",
    "        'random_read': vortex_random_read,\n",
    "        'random_repeats': RANDOM_READ_REPEATS,\n",
    "    },\n",
    "    {\n",
    "        'name': 'DuckDB (file table)',\n",
    "        'path': DUCK_PATH,\n",
    "        'write': duck_write,\n",
    "        'read': duck_read,\n",
    "        'table': duck_table,\n",
    "        'repeats': DUCK_REPEATS,\n",
    "        'random_read': duck_random_read,\n",
    "        'random_repeats': RANDOM_READ_REPEATS,\n",
    "    },\n",
    "]\n",
    "\n",
    "print('Formats:', [cfg['name'] for cfg in format_configs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c64b6b1",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[format start] Parquet (pyarrow, zstd)\n",
      "[write] Parquet (pyarrow, zstd) run 1/5: 21.08s\n",
      "[write] Parquet (pyarrow, zstd) run 2/5: 21.32s\n",
      "[write] Parquet (pyarrow, zstd) run 3/5: 20.79s\n",
      "[write] Parquet (pyarrow, zstd) run 4/5: 20.54s\n",
      "[write] Parquet (pyarrow, zstd) run 5/5: 20.52s\n",
      "[read ] Parquet (pyarrow, zstd) run 1/5: 2.29s\n",
      "[read ] Parquet (pyarrow, zstd) run 2/5: 2.39s\n",
      "[read ] Parquet (pyarrow, zstd) run 3/5: 1.43s\n",
      "[read ] Parquet (pyarrow, zstd) run 4/5: 1.85s\n",
      "[read ] Parquet (pyarrow, zstd) run 5/5: 1.16s\n",
      "[rnd  ] Parquet (pyarrow, zstd) run 1/5: 1.25s\n",
      "[rnd  ] Parquet (pyarrow, zstd) run 2/5: 1.13s\n",
      "[rnd  ] Parquet (pyarrow, zstd) run 3/5: 1.08s\n",
      "[rnd  ] Parquet (pyarrow, zstd) run 4/5: 1.06s\n",
      "[rnd  ] Parquet (pyarrow, zstd) run 5/5: 1.10s\n",
      "[format end] Parquet (pyarrow, zstd)\n",
      "[format start] Parquet (duckdb, zstd)\n",
      "[write] Parquet (duckdb, zstd) run 1/5: 15.91s\n",
      "[write] Parquet (duckdb, zstd) run 2/5: 14.82s\n",
      "[write] Parquet (duckdb, zstd) run 3/5: 14.26s\n",
      "[write] Parquet (duckdb, zstd) run 4/5: 14.63s\n",
      "[write] Parquet (duckdb, zstd) run 5/5: 14.29s\n",
      "[read ] Parquet (duckdb, zstd) run 1/5: 5.56s\n",
      "[read ] Parquet (duckdb, zstd) run 2/5: 7.43s\n",
      "[read ] Parquet (duckdb, zstd) run 3/5: 6.28s\n",
      "[read ] Parquet (duckdb, zstd) run 4/5: 6.53s\n",
      "[read ] Parquet (duckdb, zstd) run 5/5: 7.54s\n",
      "[rnd  ] Parquet (duckdb, zstd) run 1/5: 5.55s\n",
      "[rnd  ] Parquet (duckdb, zstd) run 2/5: 5.54s\n",
      "[rnd  ] Parquet (duckdb, zstd) run 3/5: 5.15s\n",
      "[rnd  ] Parquet (duckdb, zstd) run 4/5: 5.22s\n",
      "[rnd  ] Parquet (duckdb, zstd) run 5/5: 5.00s\n",
      "[format end] Parquet (duckdb, zstd)\n",
      "[format start] Lance (lancedb)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[90m[\u001b[0m2025-12-05T02:36:14Z \u001b[33mWARN \u001b[0m lance::dataset::write::insert\u001b[90m]\u001b[0m No existing dataset at /Users/buntend/Documents/work/demo-compare-parquet-vortex-lance-perf/notebooks/data/lance_db/bench.lance, it will be created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[write] Lance (lancedb) run 1/5: 5.83s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[90m[\u001b[0m2025-12-05T02:36:20Z \u001b[33mWARN \u001b[0m lance::dataset::write::insert\u001b[90m]\u001b[0m No existing dataset at /Users/buntend/Documents/work/demo-compare-parquet-vortex-lance-perf/notebooks/data/lance_db/bench.lance, it will be created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[write] Lance (lancedb) run 2/5: 5.84s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[90m[\u001b[0m2025-12-05T02:36:26Z \u001b[33mWARN \u001b[0m lance::dataset::write::insert\u001b[90m]\u001b[0m No existing dataset at /Users/buntend/Documents/work/demo-compare-parquet-vortex-lance-perf/notebooks/data/lance_db/bench.lance, it will be created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[write] Lance (lancedb) run 3/5: 5.52s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[90m[\u001b[0m2025-12-05T02:36:31Z \u001b[33mWARN \u001b[0m lance::dataset::write::insert\u001b[90m]\u001b[0m No existing dataset at /Users/buntend/Documents/work/demo-compare-parquet-vortex-lance-perf/notebooks/data/lance_db/bench.lance, it will be created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[write] Lance (lancedb) run 4/5: 5.54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[90m[\u001b[0m2025-12-05T02:36:37Z \u001b[33mWARN \u001b[0m lance::dataset::write::insert\u001b[90m]\u001b[0m No existing dataset at /Users/buntend/Documents/work/demo-compare-parquet-vortex-lance-perf/notebooks/data/lance_db/bench.lance, it will be created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[write] Lance (lancedb) run 5/5: 5.53s\n",
      "[read ] Lance (lancedb) run 1/5: 8.01s\n",
      "[read ] Lance (lancedb) run 2/5: 7.87s\n",
      "[read ] Lance (lancedb) run 3/5: 6.88s\n",
      "[read ] Lance (lancedb) run 4/5: 6.70s\n",
      "[read ] Lance (lancedb) run 5/5: 7.08s\n",
      "[rnd  ] Lance (lancedb) run 1/5: 8.38s\n",
      "[rnd  ] Lance (lancedb) run 2/5: 7.74s\n",
      "[rnd  ] Lance (lancedb) run 3/5: 7.35s\n",
      "[rnd  ] Lance (lancedb) run 4/5: 7.63s\n",
      "[rnd  ] Lance (lancedb) run 5/5: 7.82s\n",
      "[format end] Lance (lancedb)\n",
      "[format start] Vortex\n",
      "[write] Vortex run 1/5: 14.79s\n",
      "[write] Vortex run 2/5: 12.78s\n",
      "[write] Vortex run 3/5: 12.10s\n",
      "[write] Vortex run 4/5: 11.31s\n",
      "[write] Vortex run 5/5: 11.43s\n",
      "[read ] Vortex run 1/5: 0.59s\n",
      "[read ] Vortex run 2/5: 0.77s\n",
      "[read ] Vortex run 3/5: 0.79s\n",
      "[read ] Vortex run 4/5: 0.89s\n",
      "[read ] Vortex run 5/5: 0.71s\n",
      "[rnd  ] Vortex run 1/5: 0.98s\n",
      "[rnd  ] Vortex run 2/5: 0.87s\n",
      "[rnd  ] Vortex run 3/5: 0.84s\n",
      "[rnd  ] Vortex run 4/5: 0.92s\n",
      "[rnd  ] Vortex run 5/5: 0.81s\n",
      "[format end] Vortex\n",
      "[format start] DuckDB (file table)\n",
      "[write] DuckDB (file table) run 1/5: 23.32s\n",
      "[write] DuckDB (file table) run 2/5: 23.46s\n",
      "[write] DuckDB (file table) run 3/5: 22.60s\n",
      "[write] DuckDB (file table) run 4/5: 22.85s\n",
      "[write] DuckDB (file table) run 5/5: 22.57s\n",
      "[read ] DuckDB (file table) run 1/5: 4.49s\n",
      "[read ] DuckDB (file table) run 2/5: 5.68s\n",
      "[read ] DuckDB (file table) run 3/5: 5.25s\n",
      "[read ] DuckDB (file table) run 4/5: 4.37s\n",
      "[read ] DuckDB (file table) run 5/5: 4.28s\n",
      "[rnd  ] DuckDB (file table) run 1/5: 2.81s\n",
      "[rnd  ] DuckDB (file table) run 2/5: 2.21s\n",
      "[rnd  ] DuckDB (file table) run 3/5: 2.58s\n",
      "[rnd  ] DuckDB (file table) run 4/5: 2.24s\n",
      "[rnd  ] DuckDB (file table) run 5/5: 2.61s\n",
      "[format end] DuckDB (file table)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format</th>\n",
       "      <th>write_avg_s</th>\n",
       "      <th>write_std_s</th>\n",
       "      <th>read_all_avg_s</th>\n",
       "      <th>read_all_std_s</th>\n",
       "      <th>read_random_avg_s</th>\n",
       "      <th>read_random_std_s</th>\n",
       "      <th>size_mb</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Parquet (pyarrow, zstd)</td>\n",
       "      <td>20.8488</td>\n",
       "      <td>0.3085</td>\n",
       "      <td>1.8218</td>\n",
       "      <td>0.4760</td>\n",
       "      <td>1.1248</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>3743.2068</td>\n",
       "      <td>pyarrow 22.0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parquet (duckdb, zstd)</td>\n",
       "      <td>14.7816</td>\n",
       "      <td>0.6009</td>\n",
       "      <td>6.6673</td>\n",
       "      <td>0.7405</td>\n",
       "      <td>5.2894</td>\n",
       "      <td>0.2187</td>\n",
       "      <td>2943.5400</td>\n",
       "      <td>duckdb 1.4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lance (lancedb)</td>\n",
       "      <td>5.6518</td>\n",
       "      <td>0.1501</td>\n",
       "      <td>7.3063</td>\n",
       "      <td>0.5333</td>\n",
       "      <td>7.7853</td>\n",
       "      <td>0.3389</td>\n",
       "      <td>3124.5917</td>\n",
       "      <td>lancedb 0.25.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vortex</td>\n",
       "      <td>12.4819</td>\n",
       "      <td>1.2676</td>\n",
       "      <td>0.7498</td>\n",
       "      <td>0.0971</td>\n",
       "      <td>0.8859</td>\n",
       "      <td>0.0627</td>\n",
       "      <td>2769.6248</td>\n",
       "      <td>vortex 0.56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DuckDB (file table)</td>\n",
       "      <td>22.9581</td>\n",
       "      <td>0.3649</td>\n",
       "      <td>4.8133</td>\n",
       "      <td>0.5533</td>\n",
       "      <td>2.4899</td>\n",
       "      <td>0.2315</td>\n",
       "      <td>3026.2617</td>\n",
       "      <td>duckdb 1.4.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    format  write_avg_s  write_std_s  read_all_avg_s  \\\n",
       "0  Parquet (pyarrow, zstd)      20.8488       0.3085          1.8218   \n",
       "1   Parquet (duckdb, zstd)      14.7816       0.6009          6.6673   \n",
       "2          Lance (lancedb)       5.6518       0.1501          7.3063   \n",
       "3                   Vortex      12.4819       1.2676          0.7498   \n",
       "4      DuckDB (file table)      22.9581       0.3649          4.8133   \n",
       "\n",
       "   read_all_std_s  read_random_avg_s  read_random_std_s    size_mb  \\\n",
       "0          0.4760             1.1248             0.0687  3743.2068   \n",
       "1          0.7405             5.2894             0.2187  2943.5400   \n",
       "2          0.5333             7.7853             0.3389  3124.5917   \n",
       "3          0.0971             0.8859             0.0627  2769.6248   \n",
       "4          0.5533             2.4899             0.2315  3026.2617   \n",
       "\n",
       "          version  \n",
       "0  pyarrow 22.0.0  \n",
       "1    duckdb 1.4.2  \n",
       "2  lancedb 0.25.3  \n",
       "3   vortex 0.56.0  \n",
       "4    duckdb 1.4.2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = run_benchmarks(table, format_configs, repeats=REPEATS)\n",
    "results_df = pd.DataFrame({\n",
    "    'format': [r['format'] for r in results],\n",
    "    'write_avg_s': [np.mean(r['write_seconds']) for r in results],\n",
    "    'write_std_s': [np.std(r['write_seconds']) for r in results],\n",
    "    'read_all_avg_s': [np.mean(r['read_seconds']) for r in results],\n",
    "    'read_all_std_s': [np.std(r['read_seconds']) for r in results],\n",
    "    'read_random_avg_s': [np.mean(r['random_read_seconds']) for r in results],\n",
    "    'read_random_std_s': [np.std(r['random_read_seconds']) for r in results],\n",
    "    'size_mb': [r['size_mb'] for r in results],\n",
    "    'version': [FORMAT_VERSIONS.get(r['format'], '') for r in results],\n",
    "})\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d6529cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format</th>\n",
       "      <th>kind</th>\n",
       "      <th>run</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Parquet (pyarrow, zstd)</td>\n",
       "      <td>write</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parquet (pyarrow, zstd)</td>\n",
       "      <td>write</td>\n",
       "      <td>1</td>\n",
       "      <td>21.3158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Parquet (pyarrow, zstd)</td>\n",
       "      <td>write</td>\n",
       "      <td>2</td>\n",
       "      <td>20.7875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parquet (pyarrow, zstd)</td>\n",
       "      <td>write</td>\n",
       "      <td>3</td>\n",
       "      <td>20.5389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Parquet (pyarrow, zstd)</td>\n",
       "      <td>write</td>\n",
       "      <td>4</td>\n",
       "      <td>20.5240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>DuckDB (file table)</td>\n",
       "      <td>random_read</td>\n",
       "      <td>0</td>\n",
       "      <td>2.8111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>DuckDB (file table)</td>\n",
       "      <td>random_read</td>\n",
       "      <td>1</td>\n",
       "      <td>2.2119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>DuckDB (file table)</td>\n",
       "      <td>random_read</td>\n",
       "      <td>2</td>\n",
       "      <td>2.5849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>DuckDB (file table)</td>\n",
       "      <td>random_read</td>\n",
       "      <td>3</td>\n",
       "      <td>2.2352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>DuckDB (file table)</td>\n",
       "      <td>random_read</td>\n",
       "      <td>4</td>\n",
       "      <td>2.6061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     format         kind  run  seconds\n",
       "0   Parquet (pyarrow, zstd)        write    0  21.0780\n",
       "1   Parquet (pyarrow, zstd)        write    1  21.3158\n",
       "2   Parquet (pyarrow, zstd)        write    2  20.7875\n",
       "3   Parquet (pyarrow, zstd)        write    3  20.5389\n",
       "4   Parquet (pyarrow, zstd)        write    4  20.5240\n",
       "..                      ...          ...  ...      ...\n",
       "70      DuckDB (file table)  random_read    0   2.8111\n",
       "71      DuckDB (file table)  random_read    1   2.2119\n",
       "72      DuckDB (file table)  random_read    2   2.5849\n",
       "73      DuckDB (file table)  random_read    3   2.2352\n",
       "74      DuckDB (file table)  random_read    4   2.6061\n",
       "\n",
       "[75 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timings = []\n",
    "for r in results:\n",
    "    for idx, t in enumerate(r['write_seconds']):\n",
    "        timings.append({'format': r['format'], 'kind': 'write', 'run': idx, 'seconds': t})\n",
    "    for idx, t in enumerate(r['read_seconds']):\n",
    "        timings.append({'format': r['format'], 'kind': 'read', 'run': idx, 'seconds': t})\n",
    "    for idx, t in enumerate(r['random_read_seconds']):\n",
    "        timings.append({'format': r['format'], 'kind': 'random_read', 'run': idx, 'seconds': t})\n",
    "\n",
    "pd.DataFrame(timings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
