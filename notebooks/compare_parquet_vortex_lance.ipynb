{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Parquet vs. Vortex vs. Lance performance\n\n",
        "Generate a wide random dataset (~100k rows x 3k columns) and benchmark on-disk formats. Decrease `N_ROWS`/`N_COLS` if you run into memory pressure.\n\n",
        "Requires `pyarrow`, `lancedb`, and `vortex-data` (installed via uv).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Setup**\n",
        "- Run `uv run poe lab` (or `uv venv && uv sync && uv run jupyter lab`).\n",
        "- Artifacts are written under `data/` (git-ignored).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gc\n",
        "import shutil\n",
        "import time\n",
        "from pathlib import Path\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "import lancedb\n",
        "import vortex\n",
        "\n",
        "pd.set_option(\"display.precision\", 4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DATA_DIR = Path(\"data\")\n",
        "DATA_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "N_ROWS = 100_000\n",
        "N_COLS = 3_000\n",
        "DTYPE = np.float32\n",
        "REPEATS = 3\n",
        "SEED = 13\n",
        "\n",
        "PARQUET_PATH = DATA_DIR / \"wide.parquet\"\n",
        "LANCE_PATH = DATA_DIR / \"lance_db\"\n",
        "VORTEX_PATH = DATA_DIR / \"wide.vortex\"\n",
        "\n",
        "N_ROWS, N_COLS, DTYPE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rng = np.random.default_rng(SEED)\n",
        "column_names = [f\"col_{i:04d}\" for i in range(N_COLS)]\n",
        "columns = [pa.array(rng.standard_normal(N_ROWS, dtype=DTYPE)) for _ in range(N_COLS)]\n",
        "table = pa.Table.from_arrays(columns, names=column_names)\n",
        "table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def drop_path(path: Path) -> None:\n",
        "    \"\"\"Delete a file or directory if it exists.\"\"\"\n",
        "    if path.is_dir():\n",
        "        shutil.rmtree(path, ignore_errors=True)\n",
        "    elif path.exists():\n",
        "        path.unlink()\n",
        "\n",
        "\n",
        "def path_size_bytes(path: Path) -> int:\n",
        "    if path.is_file():\n",
        "        return path.stat().st_size\n",
        "    if path.is_dir():\n",
        "        return sum(p.stat().st_size for p in path.rglob(\"*\") if p.is_file())\n",
        "    return 0\n",
        "\n",
        "\n",
        "def make_vortex_writer():\n",
        "    \"\"\"Pick a vortex writer if available, otherwise raise with guidance.\"\"\"\n",
        "    writer = getattr(vortex, \"write_dataset\", None)\n",
        "    if callable(writer):\n",
        "        return writer\n",
        "    vf_write = getattr(getattr(vortex, \"VortexFile\", None), \"write\", None)\n",
        "    if callable(vf_write):\n",
        "        return vf_write\n",
        "    raise RuntimeError(\"vortex-data does not expose a write API; install a version with vortex.write_dataset or swap in the correct writer here.\")\n",
        "\n",
        "\n",
        "def run_benchmarks(table: pa.Table, configs, repeats: int = 3):\n",
        "    results = []\n",
        "    for cfg in configs:\n",
        "        write_times = []\n",
        "        read_times = []\n",
        "        for _ in range(repeats):\n",
        "            drop_path(cfg['path'])\n",
        "            t0 = time.perf_counter()\n",
        "            cfg['write'](table, cfg['path'])\n",
        "            write_times.append(time.perf_counter() - t0)\n",
        "\n",
        "        size_bytes = path_size_bytes(cfg['path'])\n",
        "\n",
        "        for _ in range(repeats):\n",
        "            gc.collect()\n",
        "            t0 = time.perf_counter()\n",
        "            _ = cfg['read'](cfg['path'])\n",
        "            read_times.append(time.perf_counter() - t0)\n",
        "\n",
        "        results.append(\n",
        "            {\n",
        "                'format': cfg['name'],\n",
        "                'write_seconds': write_times,\n",
        "                'read_seconds': read_times,\n",
        "                'size_mb': size_bytes / (1024 * 1024),\n",
        "            }\n",
        "        )\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vortex_write = make_vortex_writer()\n",
        "\n",
        "def lance_write(tbl, path=LANCE_PATH):\n",
        "    drop_path(path)\n",
        "    db = lancedb.connect(path)\n",
        "    db.create_table(\"bench\", tbl, mode=\"overwrite\")\n",
        "\n",
        "\n",
        "def lance_read(path=LANCE_PATH):\n",
        "    db = lancedb.connect(path)\n",
        "    return db.open_table(\"bench\").to_arrow()\n",
        "\n",
        "\n",
        "format_configs = [\n",
        "    {\n",
        "        'name': 'Parquet (pyarrow, zstd)',\n",
        "        'path': PARQUET_PATH,\n",
        "        'write': lambda tbl, path=PARQUET_PATH: pq.write_table(tbl, path, compression='zstd'),\n",
        "        'read': lambda path=PARQUET_PATH: pq.read_table(path),\n",
        "    },\n",
        "    {\n",
        "        'name': 'Lance (lancedb)',\n",
        "        'path': LANCE_PATH,\n",
        "        'write': lance_write,\n",
        "        'read': lance_read,\n",
        "    },\n",
        "    {\n",
        "        'name': 'Vortex',\n",
        "        'path': VORTEX_PATH,\n",
        "        'write': lambda tbl, path=VORTEX_PATH: vortex_write(tbl, path),\n",
        "        'read': lambda path=VORTEX_PATH: vortex.dataset.VortexDataset.from_path(path).to_table(),\n",
        "    },\n",
        "]\n",
        "\n",
        "format_configs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = run_benchmarks(table, format_configs, repeats=REPEATS)\n",
        "results_df = pd.DataFrame(\n",
        "    {\n",
        "        'format': [r['format'] for r in results],\n",
        "        'write_avg_s': [np.mean(r['write_seconds']) for r in results],\n",
        "        'write_std_s': [np.std(r['write_seconds']) for r in results],\n",
        "        'read_avg_s': [np.mean(r['read_seconds']) for r in results],\n",
        "        'read_std_s': [np.std(r['read_seconds']) for r in results],\n",
        "        'size_mb': [r['size_mb'] for r in results],\n",
        "    }\n",
        ")\n",
        "results_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "timings = []\n",
        "for r in results:\n",
        "    for idx, t in enumerate(r['write_seconds']):\n",
        "        timings.append({'format': r['format'], 'kind': 'write', 'run': idx, 'seconds': t})\n",
        "    for idx, t in enumerate(r['read_seconds']):\n",
        "        timings.append({'format': r['format'], 'kind': 'read', 'run': idx, 'seconds': t})\n",
        "\n",
        "pd.DataFrame(timings)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}