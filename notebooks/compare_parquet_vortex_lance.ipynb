{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8de2b4c",
   "metadata": {},
   "source": [
    "# Parquet vs. Vortex vs. Lance performance\n",
    "\n",
    "Generate a wide random dataset (~100k rows x 4k float columns + 50 string columns) and benchmark on-disk formats. Decrease `N_ROWS`/`N_COLS` if you run into memory pressure.\n",
    "\n",
    "Requires `pyarrow`, `lancedb`, `vortex-data`, `duckdb` (installed via uv).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e970c18c",
   "metadata": {},
   "source": [
    "**Setup**\n",
    "- Run `uv run poe lab` (or `uv venv && uv sync && uv run jupyter lab`).\n",
    "- Artifacts are written under `data/` (git-ignored).\n",
    "- CSV/DuckDB can be heavy at full size; sampling knobs are provided below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca5ff5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import shutil\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import lancedb\n",
    "import duckdb\n",
    "import vortex\n",
    "import vortex.io as vxio\n",
    "\n",
    "pd.set_option(\"display.precision\", 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c46d89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 4000, 50, numpy.float64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = Path(\"data\")\n",
    "shutil.rmtree(DATA_DIR, ignore_errors=True)\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "N_ROWS = 100_000\n",
    "N_COLS = 4_000  # float columns\n",
    "STR_COLS = 50\n",
    "DTYPE = np.float64\n",
    "REPEATS = 3\n",
    "SEED = 13\n",
    "\n",
    "# Downsample for heavy formats to avoid multi-GB outputs.\n",
    "RUN_CSV = True\n",
    "RUN_DUCKDB = True\n",
    "CSV_ROWS = 5_000   # set None to use full table\n",
    "DUCK_ROWS = 5_000  # set None to use full table\n",
    "CSV_REPEATS = 1\n",
    "DUCK_REPEATS = 1\n",
    "\n",
    "PARQUET_PATH = DATA_DIR / \"wide.parquet\"\n",
    "LANCE_PATH = DATA_DIR / \"lance_db\"\n",
    "VORTEX_PATH = DATA_DIR / \"wide.vortex\"\n",
    "CSV_PATH = DATA_DIR / \"wide.csv.gz\"\n",
    "DUCK_PATH = DATA_DIR / \"wide.duckdb\"\n",
    "LANCE_TABLE = \"bench\"\n",
    "DUCK_TABLE = \"bench\"\n",
    "\n",
    "N_ROWS, N_COLS, STR_COLS, DTYPE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0289329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table rows: 100000 cols: 4050\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(SEED)\n",
    "float_names = [f\"col_{i:04d}\" for i in range(N_COLS)]\n",
    "float_columns = [pa.array(rng.standard_normal(N_ROWS, dtype=DTYPE)) for _ in range(N_COLS)]\n",
    "\n",
    "str_names = [f\"str_{i:04d}\" for i in range(STR_COLS)]\n",
    "str_columns = []\n",
    "for _ in range(STR_COLS):\n",
    "    ints = rng.integers(0, 1_000_000, size=N_ROWS, dtype=np.int32)\n",
    "    strings = np.char.add('s', ints.astype(str))\n",
    "    str_columns.append(pa.array(strings))\n",
    "\n",
    "column_names = float_names + str_names\n",
    "columns = float_columns + str_columns\n",
    "table = pa.Table.from_arrays(columns, names=column_names)\n",
    "print('table rows:', table.num_rows, 'cols:', table.num_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c93805b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV sample size (rows, cols): (5000, 4050)\n"
     ]
    }
   ],
   "source": [
    "# Optional downsampled tables for CSV/DuckDB\n",
    "csv_table = table.slice(0, CSV_ROWS) if RUN_CSV and CSV_ROWS is not None else table if RUN_CSV else None\n",
    "duck_table = table.slice(0, DUCK_ROWS) if RUN_DUCKDB and DUCK_ROWS is not None else table if RUN_DUCKDB else None\n",
    "\n",
    "if RUN_CSV:\n",
    "    df_csv = csv_table.to_pandas()\n",
    "    print('CSV sample size (rows, cols):', df_csv.shape)\n",
    "else:\n",
    "    df_csv = None\n",
    "    print('CSV benchmark disabled')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "915e7b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_path(path: Path) -> None:\n",
    "    \"\"\"Delete a file or directory if it exists.\"\"\"\n",
    "    if path.is_dir():\n",
    "        shutil.rmtree(path, ignore_errors=True)\n",
    "    elif path.exists():\n",
    "        path.unlink()\n",
    "\n",
    "\n",
    "def path_size_bytes(path: Path) -> int:\n",
    "    if path.is_file():\n",
    "        return path.stat().st_size\n",
    "    if path.is_dir():\n",
    "        return sum(p.stat().st_size for p in path.rglob(\"*\") if p.is_file())\n",
    "    return 0\n",
    "\n",
    "\n",
    "def run_benchmarks(table: pa.Table, configs, repeats: int = 3):\n",
    "    results = []\n",
    "    for cfg in configs:\n",
    "        cfg_repeats = cfg.get('repeats', repeats)\n",
    "        write_times = []\n",
    "        read_times = []\n",
    "        for run_idx in range(cfg_repeats):\n",
    "            if cfg.get('cleanup', True):\n",
    "                drop_path(cfg['path'])\n",
    "            t0 = time.perf_counter()\n",
    "            cfg_table = cfg.get('table', table)\n",
    "            cfg['write'](cfg_table, cfg['path'])\n",
    "            elapsed = time.perf_counter() - t0\n",
    "            write_times.append(elapsed)\n",
    "            print(f\"[write] {cfg['name']} run {run_idx + 1}/{cfg_repeats}: {elapsed:.2f}s\", flush=True)\n",
    "\n",
    "        size_bytes = path_size_bytes(cfg['path'])\n",
    "\n",
    "        for run_idx in range(cfg_repeats):\n",
    "            gc.collect()\n",
    "            t0 = time.perf_counter()\n",
    "            _ = cfg['read'](cfg['path'])\n",
    "            elapsed = time.perf_counter() - t0\n",
    "            read_times.append(elapsed)\n",
    "            print(f\"[read ] {cfg['name']} run {run_idx + 1}/{cfg_repeats}: {elapsed:.2f}s\", flush=True)\n",
    "\n",
    "        results.append(\n",
    "            {\n",
    "                'format': cfg['name'],\n",
    "                'write_seconds': write_times,\n",
    "                'read_seconds': read_times,\n",
    "                'size_mb': size_bytes / (1024 * 1024),\n",
    "            }\n",
    "        )\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e11ee6ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a single Lance connection ahead of time to avoid connect overhead.\n",
    "drop_path(LANCE_PATH)\n",
    "LANCE_DB = lancedb.connect(LANCE_PATH)\n",
    "\n",
    "def reset_lance_table(db, table_name):\n",
    "    try:\n",
    "        if hasattr(db, 'table_names') and table_name in db.table_names():\n",
    "            if hasattr(db, 'drop_table'):\n",
    "                db.drop_table(table_name)\n",
    "            else:\n",
    "                drop_path(LANCE_PATH)\n",
    "                return lancedb.connect(LANCE_PATH)\n",
    "    except Exception:\n",
    "        drop_path(LANCE_PATH)\n",
    "        return lancedb.connect(LANCE_PATH)\n",
    "    return db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbdda0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formats: ['Parquet (pyarrow, zstd)', 'Lance (lancedb)', 'Vortex', 'CSV (pandas, gzip)', 'DuckDB (file table)']\n"
     ]
    }
   ],
   "source": [
    "def lance_write(tbl, path=LANCE_PATH, table_name=LANCE_TABLE):\n",
    "    global LANCE_DB\n",
    "    LANCE_DB = reset_lance_table(LANCE_DB, table_name)\n",
    "    LANCE_DB.create_table(table_name, tbl, mode=\"overwrite\")\n",
    "\n",
    "\n",
    "def lance_read(path=LANCE_PATH, table_name=LANCE_TABLE):\n",
    "    return LANCE_DB.open_table(table_name).to_arrow()\n",
    "\n",
    "\n",
    "def vortex_write(tbl, path=VORTEX_PATH):\n",
    "    drop_path(path)\n",
    "    vxio.write(tbl, str(path))\n",
    "\n",
    "\n",
    "def vortex_read(path=VORTEX_PATH):\n",
    "    return vortex.open(str(path)).to_arrow().read_all()\n",
    "\n",
    "\n",
    "def csv_write(tbl, path=CSV_PATH, df=df_csv):\n",
    "    drop_path(path)\n",
    "    df.to_csv(path, index=False, compression='gzip')\n",
    "\n",
    "\n",
    "def csv_read(path=CSV_PATH):\n",
    "    return pd.read_csv(path, compression='gzip')\n",
    "\n",
    "\n",
    "def duck_write(tbl, path=DUCK_PATH, table_name=DUCK_TABLE):\n",
    "    drop_path(path)\n",
    "    con = duckdb.connect(str(path))\n",
    "    con.register('tmp_tbl', tbl)\n",
    "    con.execute(f\"CREATE TABLE {table_name} AS SELECT * FROM tmp_tbl\")\n",
    "    con.close()\n",
    "\n",
    "\n",
    "def duck_read(path=DUCK_PATH, table_name=DUCK_TABLE):\n",
    "    con = duckdb.connect(str(path))\n",
    "    try:\n",
    "        return con.execute(f\"SELECT * FROM {table_name}\").arrow()\n",
    "    finally:\n",
    "        con.close()\n",
    "\n",
    "\n",
    "format_configs = [\n",
    "    {\n",
    "        'name': 'Parquet (pyarrow, zstd)',\n",
    "        'path': PARQUET_PATH,\n",
    "        'write': lambda tbl, path=PARQUET_PATH: pq.write_table(tbl, path, compression='zstd'),\n",
    "        'read': lambda path=PARQUET_PATH: pq.read_table(path),\n",
    "    },\n",
    "    {\n",
    "        'name': 'Lance (lancedb)',\n",
    "        'path': LANCE_PATH,\n",
    "        'write': lance_write,\n",
    "        'read': lance_read,\n",
    "        'cleanup': False,\n",
    "    },\n",
    "    {\n",
    "        'name': 'Vortex',\n",
    "        'path': VORTEX_PATH,\n",
    "        'write': vortex_write,\n",
    "        'read': vortex_read,\n",
    "    },\n",
    "]\n",
    "\n",
    "if RUN_CSV:\n",
    "    format_configs.append(\n",
    "        {\n",
    "            'name': 'CSV (pandas, gzip)',\n",
    "            'path': CSV_PATH,\n",
    "            'write': csv_write,\n",
    "            'read': csv_read,\n",
    "            'table': csv_table,\n",
    "            'repeats': CSV_REPEATS,\n",
    "        }\n",
    "    )\n",
    "\n",
    "if RUN_DUCKDB:\n",
    "    format_configs.append(\n",
    "        {\n",
    "            'name': 'DuckDB (file table)',\n",
    "            'path': DUCK_PATH,\n",
    "            'write': duck_write,\n",
    "            'read': duck_read,\n",
    "            'table': duck_table,\n",
    "            'repeats': DUCK_REPEATS,\n",
    "        }\n",
    "    )\n",
    "\n",
    "print('Formats:', [cfg['name'] for cfg in format_configs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d87e6fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[write] Parquet (pyarrow, zstd) run 1/3: 14.85s\n",
      "[write] Parquet (pyarrow, zstd) run 2/3: 13.64s\n",
      "[write] Parquet (pyarrow, zstd) run 3/3: 13.69s\n",
      "[read ] Parquet (pyarrow, zstd) run 1/3: 3.22s\n",
      "[read ] Parquet (pyarrow, zstd) run 2/3: 2.01s\n",
      "[read ] Parquet (pyarrow, zstd) run 3/3: 0.97s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[90m[\u001b[0m2025-12-02T22:35:46Z \u001b[33mWARN \u001b[0m lance::dataset::write::insert\u001b[90m]\u001b[0m No existing dataset at /Users/buntend/Documents/work/demo-compare-parquet-vortex-lance-perf/notebooks/data/lance_db/bench.lance, it will be created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[write] Lance (lancedb) run 1/3: 6.99s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[90m[\u001b[0m2025-12-02T22:35:53Z \u001b[33mWARN \u001b[0m lance::dataset::write::insert\u001b[90m]\u001b[0m No existing dataset at /Users/buntend/Documents/work/demo-compare-parquet-vortex-lance-perf/notebooks/data/lance_db/bench.lance, it will be created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[write] Lance (lancedb) run 2/3: 4.94s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[90m[\u001b[0m2025-12-02T22:35:59Z \u001b[33mWARN \u001b[0m lance::dataset::write::insert\u001b[90m]\u001b[0m No existing dataset at /Users/buntend/Documents/work/demo-compare-parquet-vortex-lance-perf/notebooks/data/lance_db/bench.lance, it will be created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[write] Lance (lancedb) run 3/3: 3.59s\n",
      "[read ] Lance (lancedb) run 1/3: 4.66s\n",
      "[read ] Lance (lancedb) run 2/3: 5.01s\n",
      "[read ] Lance (lancedb) run 3/3: 4.98s\n",
      "[write] Vortex run 1/3: 8.33s\n",
      "[write] Vortex run 2/3: 6.72s\n",
      "[write] Vortex run 3/3: 6.74s\n",
      "[read ] Vortex run 1/3: 1.06s\n",
      "[read ] Vortex run 2/3: 0.60s\n",
      "[read ] Vortex run 3/3: 0.59s\n",
      "[write] CSV (pandas, gzip) run 1/1: 34.78s\n",
      "[read ] CSV (pandas, gzip) run 1/1: 2.23s\n",
      "[write] DuckDB (file table) run 1/1: 1.61s\n",
      "[read ] DuckDB (file table) run 1/1: 0.14s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format</th>\n",
       "      <th>write_avg_s</th>\n",
       "      <th>write_std_s</th>\n",
       "      <th>read_avg_s</th>\n",
       "      <th>read_std_s</th>\n",
       "      <th>size_mb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Parquet (pyarrow, zstd)</td>\n",
       "      <td>14.0588</td>\n",
       "      <td>0.5571</td>\n",
       "      <td>2.0674</td>\n",
       "      <td>0.9200</td>\n",
       "      <td>3742.9114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lance (lancedb)</td>\n",
       "      <td>5.1737</td>\n",
       "      <td>1.3992</td>\n",
       "      <td>4.8847</td>\n",
       "      <td>0.1570</td>\n",
       "      <td>3123.8285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vortex</td>\n",
       "      <td>7.2661</td>\n",
       "      <td>0.7541</td>\n",
       "      <td>0.7511</td>\n",
       "      <td>0.2206</td>\n",
       "      <td>2769.6237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSV (pandas, gzip)</td>\n",
       "      <td>34.7804</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>2.2322</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>173.8194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DuckDB (file table)</td>\n",
       "      <td>1.6101</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1362</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>181.0117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    format  write_avg_s  write_std_s  read_avg_s  read_std_s  \\\n",
       "0  Parquet (pyarrow, zstd)      14.0588       0.5571      2.0674      0.9200   \n",
       "1          Lance (lancedb)       5.1737       1.3992      4.8847      0.1570   \n",
       "2                   Vortex       7.2661       0.7541      0.7511      0.2206   \n",
       "3       CSV (pandas, gzip)      34.7804       0.0000      2.2322      0.0000   \n",
       "4      DuckDB (file table)       1.6101       0.0000      0.1362      0.0000   \n",
       "\n",
       "     size_mb  \n",
       "0  3742.9114  \n",
       "1  3123.8285  \n",
       "2  2769.6237  \n",
       "3   173.8194  \n",
       "4   181.0117  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = run_benchmarks(table, format_configs, repeats=REPEATS)\n",
    "results_df = pd.DataFrame(\n",
    "    {\n",
    "        'format': [r['format'] for r in results],\n",
    "        'write_avg_s': [np.mean(r['write_seconds']) for r in results],\n",
    "        'write_std_s': [np.std(r['write_seconds']) for r in results],\n",
    "        'read_avg_s': [np.mean(r['read_seconds']) for r in results],\n",
    "        'read_std_s': [np.std(r['read_seconds']) for r in results],\n",
    "        'size_mb': [r['size_mb'] for r in results],\n",
    "    }\n",
    ")\n",
    "results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "717f3873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format</th>\n",
       "      <th>kind</th>\n",
       "      <th>run</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Parquet (pyarrow, zstd)</td>\n",
       "      <td>write</td>\n",
       "      <td>0</td>\n",
       "      <td>14.8462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parquet (pyarrow, zstd)</td>\n",
       "      <td>write</td>\n",
       "      <td>1</td>\n",
       "      <td>13.6425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Parquet (pyarrow, zstd)</td>\n",
       "      <td>write</td>\n",
       "      <td>2</td>\n",
       "      <td>13.6877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parquet (pyarrow, zstd)</td>\n",
       "      <td>read</td>\n",
       "      <td>0</td>\n",
       "      <td>3.2206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Parquet (pyarrow, zstd)</td>\n",
       "      <td>read</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Parquet (pyarrow, zstd)</td>\n",
       "      <td>read</td>\n",
       "      <td>2</td>\n",
       "      <td>0.9691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Lance (lancedb)</td>\n",
       "      <td>write</td>\n",
       "      <td>0</td>\n",
       "      <td>6.9939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lance (lancedb)</td>\n",
       "      <td>write</td>\n",
       "      <td>1</td>\n",
       "      <td>4.9356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lance (lancedb)</td>\n",
       "      <td>write</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lance (lancedb)</td>\n",
       "      <td>read</td>\n",
       "      <td>0</td>\n",
       "      <td>4.6634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lance (lancedb)</td>\n",
       "      <td>read</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Lance (lancedb)</td>\n",
       "      <td>read</td>\n",
       "      <td>2</td>\n",
       "      <td>4.9804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Vortex</td>\n",
       "      <td>write</td>\n",
       "      <td>0</td>\n",
       "      <td>8.3325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Vortex</td>\n",
       "      <td>write</td>\n",
       "      <td>1</td>\n",
       "      <td>6.7241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Vortex</td>\n",
       "      <td>write</td>\n",
       "      <td>2</td>\n",
       "      <td>6.7416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Vortex</td>\n",
       "      <td>read</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Vortex</td>\n",
       "      <td>read</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Vortex</td>\n",
       "      <td>read</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CSV (pandas, gzip)</td>\n",
       "      <td>write</td>\n",
       "      <td>0</td>\n",
       "      <td>34.7804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>CSV (pandas, gzip)</td>\n",
       "      <td>read</td>\n",
       "      <td>0</td>\n",
       "      <td>2.2322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DuckDB (file table)</td>\n",
       "      <td>write</td>\n",
       "      <td>0</td>\n",
       "      <td>1.6101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DuckDB (file table)</td>\n",
       "      <td>read</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1362</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     format   kind  run  seconds\n",
       "0   Parquet (pyarrow, zstd)  write    0  14.8462\n",
       "1   Parquet (pyarrow, zstd)  write    1  13.6425\n",
       "2   Parquet (pyarrow, zstd)  write    2  13.6877\n",
       "3   Parquet (pyarrow, zstd)   read    0   3.2206\n",
       "4   Parquet (pyarrow, zstd)   read    1   2.0124\n",
       "5   Parquet (pyarrow, zstd)   read    2   0.9691\n",
       "6           Lance (lancedb)  write    0   6.9939\n",
       "7           Lance (lancedb)  write    1   4.9356\n",
       "8           Lance (lancedb)  write    2   3.5915\n",
       "9           Lance (lancedb)   read    0   4.6634\n",
       "10          Lance (lancedb)   read    1   5.0104\n",
       "11          Lance (lancedb)   read    2   4.9804\n",
       "12                   Vortex  write    0   8.3325\n",
       "13                   Vortex  write    1   6.7241\n",
       "14                   Vortex  write    2   6.7416\n",
       "15                   Vortex   read    0   1.0629\n",
       "16                   Vortex   read    1   0.6023\n",
       "17                   Vortex   read    2   0.5881\n",
       "18       CSV (pandas, gzip)  write    0  34.7804\n",
       "19       CSV (pandas, gzip)   read    0   2.2322\n",
       "20      DuckDB (file table)  write    0   1.6101\n",
       "21      DuckDB (file table)   read    0   0.1362"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timings = []\n",
    "for r in results:\n",
    "    for idx, t in enumerate(r['write_seconds']):\n",
    "        timings.append({'format': r['format'], 'kind': 'write', 'run': idx, 'seconds': t})\n",
    "    for idx, t in enumerate(r['read_seconds']):\n",
    "        timings.append({'format': r['format'], 'kind': 'read', 'run': idx, 'seconds': t})\n",
    "\n",
    "pd.DataFrame(timings)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
