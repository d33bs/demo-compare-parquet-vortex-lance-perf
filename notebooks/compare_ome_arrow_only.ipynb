{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4b0ac3d",
   "metadata": {},
   "source": [
    "# OME-Arrow single-column benchmarks\n",
    "\n",
    "Compare on-disk formats for a table containing only `row_id` and one OME-Arrow image column, plus a separate benchmark for a directory-per-image OME-Zarr layout.\n",
    "Measures: write all, read all, random-read some, size on disk.\n",
    "\n",
    "Requires `pyarrow`, `lancedb`, `vortex-data`, `duckdb`, `ome-arrow` (installed via uv). OME-Zarr export requires optional deps (`bioio-ome-zarr`, `zarr`, `numcodecs`).\n",
    "\n",
    "**Setup**\n",
    "- Run `uv run poe lab` (or `uv venv && uv sync && uv run jupyter lab`).\n",
    "- Artifacts are written under `data/` (git-ignored).\n",
    "- If you want the OME-Zarr timings, install the extra deps: `uv pip install bioio-ome-zarr zarr numcodecs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b539f49d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import shutil\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.dataset as ds\n",
    "import lancedb\n",
    "import duckdb\n",
    "import vortex\n",
    "import vortex.io as vxio\n",
    "from ome_arrow import OMEArrow\n",
    "\n",
    "pd.set_option(\"display.precision\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38e7da5d",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"data\")\n",
    "shutil.rmtree(DATA_DIR, ignore_errors=True)\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "N_ROWS = 1_000\n",
    "OME_SHAPE = (100, 100)\n",
    "OME_DTYPE = np.uint8\n",
    "REPEATS = 5\n",
    "RANDOM_READ_REPEATS = REPEATS\n",
    "RANDOM_ROW_COUNT = 10\n",
    "SEED = 13\n",
    "\n",
    "RUN_DUCKDB = True\n",
    "DUCK_ROWS = None  # use full table\n",
    "DUCK_REPEATS = REPEATS\n",
    "\n",
    "PARQUET_PATH = DATA_DIR / \"ome_only.parquet\"\n",
    "PARQUET_DUCK_PATH = DATA_DIR / \"ome_only_duck.parquet\"\n",
    "LANCE_PATH = DATA_DIR / \"ome_only_lance\"\n",
    "VORTEX_PATH = DATA_DIR / \"ome_only.vortex\"\n",
    "DUCK_PATH = DATA_DIR / \"ome_only.duckdb\"\n",
    "OME_ZARR_DIR = DATA_DIR / \"ome_zarr_runs\"\n",
    "LANCE_TABLE = \"bench\"\n",
    "DUCK_TABLE = \"bench\"\n",
    "\n",
    "# Resolve versions\n",
    "try:\n",
    "    import importlib.metadata as importlib_metadata\n",
    "except ImportError:\n",
    "    import importlib_metadata\n",
    "\n",
    "\n",
    "def _pkg_version(name: str, default: str = 'missing') -> str:\n",
    "    try:\n",
    "        return importlib_metadata.version(name)\n",
    "    except importlib_metadata.PackageNotFoundError:\n",
    "        return default\n",
    "\n",
    "try:\n",
    "    vortex_version = getattr(vortex, '__version__', None) or importlib_metadata.version('vortex-data')\n",
    "except importlib_metadata.PackageNotFoundError:\n",
    "    try:\n",
    "        vortex_version = importlib_metadata.version('vortex')\n",
    "    except importlib_metadata.PackageNotFoundError:\n",
    "        vortex_version = 'unknown'\n",
    "\n",
    "VERSIONS = {\n",
    "    'pyarrow': pa.__version__,\n",
    "    'lancedb': getattr(lancedb, '__version__', 'unknown'),\n",
    "    'duckdb': duckdb.__version__,\n",
    "    'vortex': vortex_version,\n",
    "    'ome-arrow': getattr(__import__('ome_arrow'), '__version__', 'unknown'),\n",
    "    'bioio_ome_zarr': _pkg_version('bioio-ome-zarr'),\n",
    "    'zarr': _pkg_version('zarr'),\n",
    "    'numcodecs': _pkg_version('numcodecs'),\n",
    "}\n",
    "FORMAT_VERSIONS = {\n",
    "    'Parquet (pyarrow, zstd)': f\"pyarrow {VERSIONS['pyarrow']}\",\n",
    "    'Parquet (duckdb, zstd)': f\"duckdb {VERSIONS['duckdb']}\",\n",
    "    'Lance (lancedb)': f\"lancedb {VERSIONS['lancedb']}\",\n",
    "    'Vortex': f\"vortex {VERSIONS['vortex']}\",\n",
    "    'DuckDB (file table)': f\"duckdb {VERSIONS['duckdb']}\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "760acfb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "table rows: 1000 cols: 2\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng(SEED)\n",
    "# Add an explicit row id column so we can filter for random access reads later.\n",
    "row_ids = pa.array(np.arange(N_ROWS, dtype=np.int64))\n",
    "\n",
    "# Build the OME-Arrow column with random images.\n",
    "# OMEArrow defaults to dim_order=\"TCZYX\", so we supply a 5D array with singleton T,C,Z.\n",
    "ome_pylist = []\n",
    "for _ in range(N_ROWS):\n",
    "    img = rng.integers(0, 256, size=(1, 1, 1, *OME_SHAPE), dtype=OME_DTYPE)\n",
    "    ome_scalar = OMEArrow(data=img).data.as_py()\n",
    "    ome_scalar.pop('masks', None)  # drop Null field to avoid Arrow null append issue\n",
    "    ome_pylist.append(ome_scalar)\n",
    "ome_column = pa.array(ome_pylist)\n",
    "\n",
    "column_names = ['ome_image']\n",
    "columns = [row_ids, ome_column]\n",
    "column_names = ['row_id'] + column_names\n",
    "table = pa.Table.from_arrays(columns, names=column_names)\n",
    "print('table rows:', table.num_rows, 'cols:', table.num_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c109ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "duck_table = table\n",
    "RANDOM_INDICES = sorted(rng.choice(table.num_rows, size=RANDOM_ROW_COUNT, replace=False).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eaabc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_path(path: Path) -> None:\n",
    "    if path.is_dir():\n",
    "        shutil.rmtree(path, ignore_errors=True)\n",
    "    elif path.exists():\n",
    "        path.unlink()\n",
    "\n",
    "\n",
    "def path_size_bytes(path: Path) -> int:\n",
    "    if path.is_file():\n",
    "        return path.stat().st_size\n",
    "    if path.is_dir():\n",
    "        return sum(p.stat().st_size for p in path.rglob('*') if p.is_file())\n",
    "    return 0\n",
    "\n",
    "\n",
    "def run_benchmarks(table: pa.Table, configs, repeats: int = 3):\n",
    "    results = []\n",
    "    for cfg in configs:\n",
    "        cfg_repeats = cfg.get('repeats', repeats)\n",
    "        cfg_random_repeats = cfg.get('random_repeats', cfg_repeats)\n",
    "        write_times = []\n",
    "        read_times = []\n",
    "        random_read_times = []\n",
    "        print(f\"[format start] {cfg['name']}\", flush=True)\n",
    "        for run_idx in range(cfg_repeats):\n",
    "            if cfg.get('cleanup', True):\n",
    "                drop_path(cfg['path'])\n",
    "            t0 = time.perf_counter()\n",
    "            cfg_table = cfg.get('table', table)\n",
    "            cfg['write'](cfg_table, cfg['path'])\n",
    "            elapsed = time.perf_counter() - t0\n",
    "            write_times.append(elapsed)\n",
    "            print(f\"[write] {cfg['name']} run {run_idx + 1}/{cfg_repeats}: {elapsed:.2f}s\", flush=True)\n",
    "\n",
    "        size_bytes = path_size_bytes(cfg['path'])\n",
    "\n",
    "        for run_idx in range(cfg_repeats):\n",
    "            gc.collect()\n",
    "            t0 = time.perf_counter()\n",
    "            _ = cfg['read'](cfg['path'])\n",
    "            elapsed = time.perf_counter() - t0\n",
    "            read_times.append(elapsed)\n",
    "            print(f\"[read ] {cfg['name']} run {run_idx + 1}/{cfg_repeats}: {elapsed:.2f}s\", flush=True)\n",
    "\n",
    "        for run_idx in range(cfg_random_repeats):\n",
    "            gc.collect()\n",
    "            t0 = time.perf_counter()\n",
    "            random_fn = cfg.get('random_read')\n",
    "            if random_fn is None:\n",
    "                tbl = cfg['read'](cfg['path'])\n",
    "                _ = tbl.take(RANDOM_INDICES)\n",
    "            else:\n",
    "                _ = random_fn(cfg['path'], indices=RANDOM_INDICES)\n",
    "            elapsed = time.perf_counter() - t0\n",
    "            random_read_times.append(elapsed)\n",
    "            print(f\"[rnd  ] {cfg['name']} run {run_idx + 1}/{cfg_random_repeats}: {elapsed:.2f}s\", flush=True)\n",
    "\n",
    "        results.append({\n",
    "            'format': cfg['name'],\n",
    "            'write_seconds': write_times,\n",
    "            'read_seconds': read_times,\n",
    "            'random_read_seconds': random_read_times,\n",
    "            'size_mb': size_bytes / (1024 * 1024),\n",
    "        })\n",
    "        print(f\"[format end] {cfg['name']}\", flush=True)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20b88100",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_path(LANCE_PATH)\n",
    "LANCE_DB = lancedb.connect(LANCE_PATH)\n",
    "\n",
    "def reset_lance_table(db, table_name):\n",
    "    try:\n",
    "        if hasattr(db, 'table_names') and table_name in db.table_names():\n",
    "            if hasattr(db, 'drop_table'):\n",
    "                db.drop_table(table_name)\n",
    "            else:\n",
    "                drop_path(LANCE_PATH)\n",
    "                return lancedb.connect(LANCE_PATH)\n",
    "    except Exception:\n",
    "        drop_path(LANCE_PATH)\n",
    "        return lancedb.connect(LANCE_PATH)\n",
    "    return db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "311f80ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formats: ['Parquet (pyarrow, zstd)', 'Parquet (duckdb, zstd)', 'Lance (lancedb)', 'Vortex', 'DuckDB (file table)', 'OME-Zarr (dir-per-image)']\n"
     ]
    }
   ],
   "source": [
    "def lance_write(tbl, path=LANCE_PATH, table_name=LANCE_TABLE):\n",
    "    global LANCE_DB\n",
    "    LANCE_DB = reset_lance_table(LANCE_DB, table_name)\n",
    "    LANCE_DB.create_table(table_name, tbl, mode=\"overwrite\")\n",
    "\n",
    "\n",
    "def lance_read(path=LANCE_PATH, table_name=LANCE_TABLE):\n",
    "    return LANCE_DB.open_table(table_name).to_arrow()\n",
    "\n",
    "\n",
    "def vortex_write(tbl, path=VORTEX_PATH):\n",
    "    drop_path(path)\n",
    "    vxio.write(tbl, str(path))\n",
    "\n",
    "\n",
    "def vortex_read(path=VORTEX_PATH):\n",
    "    return vortex.open(str(path)).to_arrow().read_all()\n",
    "\n",
    "\n",
    "def duck_write(tbl, path=DUCK_PATH, table_name=DUCK_TABLE):\n",
    "    drop_path(path)\n",
    "    con = duckdb.connect(str(path))\n",
    "    con.register('tmp_tbl', tbl)\n",
    "    con.execute(f\"CREATE TABLE {table_name} AS SELECT * FROM tmp_tbl\")\n",
    "    con.close()\n",
    "\n",
    "\n",
    "def duck_read(path=DUCK_PATH, table_name=DUCK_TABLE):\n",
    "    with duckdb.connect(str(path)) as con:\n",
    "        return con.execute(f\"SELECT * FROM {table_name}\").fetch_arrow_table()\n",
    "\n",
    "\n",
    "def parquet_duck_write(tbl, path=PARQUET_DUCK_PATH):\n",
    "    drop_path(path)\n",
    "    con = duckdb.connect()\n",
    "    con.register('tmp_tbl', tbl)\n",
    "    con.execute(f\"COPY (SELECT * FROM tmp_tbl) TO '{path}' WITH (FORMAT 'PARQUET', COMPRESSION 'ZSTD')\")\n",
    "    con.close()\n",
    "\n",
    "\n",
    "def parquet_duck_read(path=PARQUET_DUCK_PATH):\n",
    "    with duckdb.connect() as con:\n",
    "        return con.execute(f\"SELECT * FROM read_parquet('{path}')\").fetch_arrow_table()\n",
    "\n",
    "\n",
    "def parquet_random_read(path=PARQUET_PATH, indices=None):\n",
    "    try:\n",
    "        dataset = ds.dataset(path, format=\"parquet\")\n",
    "        filt = ds.field('row_id').isin(pa.array(indices, type=pa.int64()))\n",
    "        return dataset.to_table(filter=filt)\n",
    "    except Exception:\n",
    "        return pq.read_table(path).take(indices)\n",
    "\n",
    "\n",
    "def parquet_duck_random_read(path=PARQUET_DUCK_PATH, indices=None):\n",
    "    idx_list = \",\".join(str(int(i)) for i in indices)\n",
    "    with duckdb.connect() as con:\n",
    "        return con.execute(f\"SELECT * FROM read_parquet('{path}') WHERE row_id IN ({idx_list})\").fetch_arrow_table()\n",
    "\n",
    "\n",
    "def lance_random_read(path=LANCE_PATH, table_name=LANCE_TABLE, indices=None):\n",
    "    idx_list = \",\".join(str(int(i)) for i in indices)\n",
    "    table = LANCE_DB.open_table(table_name)\n",
    "    try:\n",
    "        return table.query().where(f\"row_id IN ({idx_list})\").to_arrow()\n",
    "    except Exception:\n",
    "        return table.to_arrow().take(indices)\n",
    "\n",
    "\n",
    "def vortex_random_read(path=VORTEX_PATH, indices=None):\n",
    "    reader = vortex.open(str(path)).to_arrow()\n",
    "    target = sorted(int(i) for i in indices)\n",
    "    collected = None\n",
    "    offset = 0\n",
    "    for batch in reader:\n",
    "        batch_len = batch.num_rows\n",
    "        batch_matches = [idx - offset for idx in target if offset <= idx < offset + batch_len]\n",
    "        if not batch_matches:\n",
    "            offset += batch_len\n",
    "            continue\n",
    "        if collected is None:\n",
    "            collected = {name: [] for name in batch.schema.names}\n",
    "        for name, column in zip(batch.schema.names, batch.columns):\n",
    "            for rel_idx in batch_matches:\n",
    "                collected[name].append(column[rel_idx].as_py())\n",
    "        offset += batch_len\n",
    "        if len(next(iter(collected.values()))) >= len(target):\n",
    "            break\n",
    "    if not collected:\n",
    "        return pa.Table.from_arrays([], names=[])\n",
    "    arrays = [pa.array(collected[name]) for name in collected.keys()]\n",
    "    return pa.Table.from_arrays(arrays, names=list(collected.keys()))\n",
    "\n",
    "\n",
    "def duck_random_read(path=DUCK_PATH, table_name=DUCK_TABLE, indices=None):\n",
    "    idx_list = \",\".join(str(int(i)) for i in indices)\n",
    "    with duckdb.connect(str(path)) as con:\n",
    "        return con.execute(f\"SELECT * FROM {table_name} WHERE row_id IN ({idx_list})\").fetch_arrow_table()\n",
    "\n",
    "\n",
    "# OME-Zarr helpers (dir-per-image)\n",
    "def ome_zarr_deps_available() -> bool:\n",
    "    try:\n",
    "        import bioio_ome_zarr  # noqa: F401\n",
    "        import zarr  # noqa: F401\n",
    "        import numcodecs  # noqa: F401\n",
    "        return True\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "\n",
    "def ome_zarr_write_all(records, base_path=OME_ZARR_DIR):\n",
    "    if not ome_zarr_deps_available():\n",
    "        raise RuntimeError(\"OME-Zarr deps missing: install bioio-ome-zarr zarr numcodecs\")\n",
    "    drop_path(base_path)\n",
    "    base_path.mkdir(parents=True, exist_ok=True)\n",
    "    from ome_arrow import to_ome_zarr\n",
    "    for idx, rec in enumerate(records):\n",
    "        out_dir = base_path / f\"img_{idx:05d}.zarr\"\n",
    "        to_ome_zarr(rec, str(out_dir))\n",
    "\n",
    "\n",
    "def ome_zarr_read_all(base_path=OME_ZARR_DIR):\n",
    "    if not ome_zarr_deps_available():\n",
    "        raise RuntimeError(\"OME-Zarr deps missing: install bioio-ome-zarr zarr numcodecs\")\n",
    "    from ome_arrow import from_ome_zarr\n",
    "    out = []\n",
    "    for zarr_dir in sorted(base_path.glob(\"*.zarr\")):\n",
    "        out.append(from_ome_zarr(str(zarr_dir)))\n",
    "    return out\n",
    "\n",
    "\n",
    "def ome_zarr_random_read(indices, base_path=OME_ZARR_DIR):\n",
    "    if not ome_zarr_deps_available():\n",
    "        raise RuntimeError(\"OME-Zarr deps missing: install bioio-ome-zarr zarr numcodecs\")\n",
    "    from ome_arrow import from_ome_zarr\n",
    "    paths = sorted(base_path.glob(\"*.zarr\"))\n",
    "    out = []\n",
    "    for idx in indices:\n",
    "        if 0 <= idx < len(paths):\n",
    "            out.append(from_ome_zarr(str(paths[idx])))\n",
    "    return out\n",
    "\n",
    "\n",
    "format_configs = [\n",
    "    {\n",
    "        'name': 'Parquet (pyarrow, zstd)',\n",
    "        'path': PARQUET_PATH,\n",
    "        'write': lambda tbl, path=PARQUET_PATH: pq.write_table(tbl, path, compression='zstd'),\n",
    "        'read': lambda path=PARQUET_PATH: pq.read_table(path),\n",
    "        'random_read': parquet_random_read,\n",
    "        'random_repeats': RANDOM_READ_REPEATS,\n",
    "    },\n",
    "    {\n",
    "        'name': 'Parquet (duckdb, zstd)',\n",
    "        'path': PARQUET_DUCK_PATH,\n",
    "        'write': parquet_duck_write,\n",
    "        'read': parquet_duck_read,\n",
    "        'random_read': parquet_duck_random_read,\n",
    "        'random_repeats': RANDOM_READ_REPEATS,\n",
    "    },\n",
    "    {\n",
    "        'name': 'Lance (lancedb)',\n",
    "        'path': LANCE_PATH,\n",
    "        'write': lance_write,\n",
    "        'read': lance_read,\n",
    "        'cleanup': False,\n",
    "        'random_read': lance_random_read,\n",
    "        'random_repeats': RANDOM_READ_REPEATS,\n",
    "    },\n",
    "    {\n",
    "        'name': 'Vortex',\n",
    "        'path': VORTEX_PATH,\n",
    "        'write': vortex_write,\n",
    "        'read': vortex_read,\n",
    "        'random_read': vortex_random_read,\n",
    "        'random_repeats': RANDOM_READ_REPEATS,\n",
    "    },\n",
    "    {\n",
    "        'name': 'DuckDB (file table)',\n",
    "        'path': DUCK_PATH,\n",
    "        'write': duck_write,\n",
    "        'read': duck_read,\n",
    "        'table': duck_table,\n",
    "        'repeats': DUCK_REPEATS,\n",
    "        'random_read': duck_random_read,\n",
    "        'random_repeats': RANDOM_READ_REPEATS,\n",
    "    },\n",
    "]\n",
    "\n",
    "if ome_zarr_deps_available():\n",
    "    format_configs.append({\n",
    "        'name': 'OME-Zarr (dir-per-image)',\n",
    "        'path': OME_ZARR_DIR,\n",
    "        'write': lambda records, path=OME_ZARR_DIR: ome_zarr_write_all(records, path),\n",
    "        'read': lambda path=OME_ZARR_DIR: ome_zarr_read_all(path),\n",
    "        'random_read': lambda path=OME_ZARR_DIR, indices=None: ome_zarr_random_read(indices, path),\n",
    "        'table': ome_pylist,  # run_benchmarks passes as cfg_table; here it's a list of records\n",
    "        'random_repeats': RANDOM_READ_REPEATS,\n",
    "        'version': (\n",
    "            f\"ome-arrow {VERSIONS.get('ome-arrow', '')}; \"\n",
    "            f\"bioio-ome-zarr {VERSIONS.get('bioio_ome_zarr', '')}; \"\n",
    "            f\"zarr {VERSIONS.get('zarr', '')}; \"\n",
    "            f\"numcodecs {VERSIONS.get('numcodecs', '')}\"\n",
    "        ),\n",
    "    })\n",
    "else:\n",
    "    print(\"Skipping OME-Zarr format (install bioio-ome-zarr zarr numcodecs to enable).\")\n",
    "\n",
    "print('Formats:', [cfg['name'] for cfg in format_configs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a80a0d7",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[format start] Parquet (pyarrow, zstd)\n",
      "[write] Parquet (pyarrow, zstd) run 1/5: 0.12s\n",
      "[write] Parquet (pyarrow, zstd) run 2/5: 0.10s\n",
      "[write] Parquet (pyarrow, zstd) run 3/5: 0.10s\n",
      "[write] Parquet (pyarrow, zstd) run 4/5: 0.10s\n",
      "[write] Parquet (pyarrow, zstd) run 5/5: 0.09s\n",
      "[read ] Parquet (pyarrow, zstd) run 1/5: 0.05s\n",
      "[read ] Parquet (pyarrow, zstd) run 2/5: 0.05s\n",
      "[read ] Parquet (pyarrow, zstd) run 3/5: 0.06s\n",
      "[read ] Parquet (pyarrow, zstd) run 4/5: 0.06s\n",
      "[read ] Parquet (pyarrow, zstd) run 5/5: 0.05s\n",
      "[rnd  ] Parquet (pyarrow, zstd) run 1/5: 0.06s\n",
      "[rnd  ] Parquet (pyarrow, zstd) run 2/5: 0.05s\n",
      "[rnd  ] Parquet (pyarrow, zstd) run 3/5: 0.04s\n",
      "[rnd  ] Parquet (pyarrow, zstd) run 4/5: 0.04s\n",
      "[rnd  ] Parquet (pyarrow, zstd) run 5/5: 0.05s\n",
      "[format end] Parquet (pyarrow, zstd)\n",
      "[format start] Parquet (duckdb, zstd)\n",
      "[write] Parquet (duckdb, zstd) run 1/5: 0.26s\n",
      "[write] Parquet (duckdb, zstd) run 2/5: 0.24s\n",
      "[write] Parquet (duckdb, zstd) run 3/5: 0.23s\n",
      "[write] Parquet (duckdb, zstd) run 4/5: 0.22s\n",
      "[write] Parquet (duckdb, zstd) run 5/5: 0.22s\n",
      "[read ] Parquet (duckdb, zstd) run 1/5: 0.21s\n",
      "[read ] Parquet (duckdb, zstd) run 2/5: 0.20s\n",
      "[read ] Parquet (duckdb, zstd) run 3/5: 0.18s\n",
      "[read ] Parquet (duckdb, zstd) run 4/5: 0.18s\n",
      "[read ] Parquet (duckdb, zstd) run 5/5: 0.20s\n",
      "[rnd  ] Parquet (duckdb, zstd) run 1/5: 0.14s\n",
      "[rnd  ] Parquet (duckdb, zstd) run 2/5: 0.14s\n",
      "[rnd  ] Parquet (duckdb, zstd) run 3/5: 0.14s\n",
      "[rnd  ] Parquet (duckdb, zstd) run 4/5: 0.14s\n",
      "[rnd  ] Parquet (duckdb, zstd) run 5/5: 0.14s\n",
      "[format end] Parquet (duckdb, zstd)\n",
      "[format start] Lance (lancedb)\n",
      "[write] Lance (lancedb) run 1/5: 0.10s\n",
      "[write] Lance (lancedb) run 2/5: 0.04s\n",
      "[write] Lance (lancedb) run 3/5: 0.04s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[90m[\u001b[0m2025-12-10T14:55:34Z \u001b[33mWARN \u001b[0m lance::dataset::write::insert\u001b[90m]\u001b[0m No existing dataset at /Users/buntend/Documents/work/demo-compare-parquet-vortex-lance-perf/notebooks/data/ome_only_lance/bench.lance, it will be created\n",
      "\u001b[90m[\u001b[0m2025-12-10T14:55:34Z \u001b[33mWARN \u001b[0m lance::dataset::write::insert\u001b[90m]\u001b[0m No existing dataset at /Users/buntend/Documents/work/demo-compare-parquet-vortex-lance-perf/notebooks/data/ome_only_lance/bench.lance, it will be created\n",
      "\u001b[90m[\u001b[0m2025-12-10T14:55:34Z \u001b[33mWARN \u001b[0m lance::dataset::write::insert\u001b[90m]\u001b[0m No existing dataset at /Users/buntend/Documents/work/demo-compare-parquet-vortex-lance-perf/notebooks/data/ome_only_lance/bench.lance, it will be created\n",
      "\u001b[90m[\u001b[0m2025-12-10T14:55:34Z \u001b[33mWARN \u001b[0m lance::dataset::write::insert\u001b[90m]\u001b[0m No existing dataset at /Users/buntend/Documents/work/demo-compare-parquet-vortex-lance-perf/notebooks/data/ome_only_lance/bench.lance, it will be created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[write] Lance (lancedb) run 4/5: 0.04s\n",
      "[write] Lance (lancedb) run 5/5: 0.04s\n",
      "[read ] Lance (lancedb) run 1/5: 0.06s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[90m[\u001b[0m2025-12-10T14:55:34Z \u001b[33mWARN \u001b[0m lance::dataset::write::insert\u001b[90m]\u001b[0m No existing dataset at /Users/buntend/Documents/work/demo-compare-parquet-vortex-lance-perf/notebooks/data/ome_only_lance/bench.lance, it will be created\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[read ] Lance (lancedb) run 2/5: 0.02s\n",
      "[read ] Lance (lancedb) run 3/5: 0.02s\n",
      "[read ] Lance (lancedb) run 4/5: 0.02s\n",
      "[read ] Lance (lancedb) run 5/5: 0.02s\n",
      "[rnd  ] Lance (lancedb) run 1/5: 0.02s\n",
      "[rnd  ] Lance (lancedb) run 2/5: 0.02s\n",
      "[rnd  ] Lance (lancedb) run 3/5: 0.02s\n",
      "[rnd  ] Lance (lancedb) run 4/5: 0.02s\n",
      "[rnd  ] Lance (lancedb) run 5/5: 0.02s\n",
      "[format end] Lance (lancedb)\n",
      "[format start] Vortex\n",
      "[write] Vortex run 1/5: 0.08s\n",
      "[write] Vortex run 2/5: 0.06s\n",
      "[write] Vortex run 3/5: 0.06s\n",
      "[write] Vortex run 4/5: 0.07s\n",
      "[write] Vortex run 5/5: 0.06s\n",
      "[read ] Vortex run 1/5: 0.02s\n",
      "[read ] Vortex run 2/5: 0.01s\n",
      "[read ] Vortex run 3/5: 0.01s\n",
      "[read ] Vortex run 4/5: 0.01s\n",
      "[read ] Vortex run 5/5: 0.01s\n",
      "[rnd  ] Vortex run 1/5: 0.03s\n",
      "[rnd  ] Vortex run 2/5: 0.03s\n",
      "[rnd  ] Vortex run 3/5: 0.03s\n",
      "[rnd  ] Vortex run 4/5: 0.03s\n",
      "[rnd  ] Vortex run 5/5: 0.02s\n",
      "[format end] Vortex\n",
      "[format start] DuckDB (file table)\n",
      "[write] DuckDB (file table) run 1/5: 0.20s\n",
      "[write] DuckDB (file table) run 2/5: 0.18s\n",
      "[write] DuckDB (file table) run 3/5: 0.18s\n",
      "[write] DuckDB (file table) run 4/5: 0.18s\n",
      "[write] DuckDB (file table) run 5/5: 0.19s\n",
      "[read ] DuckDB (file table) run 1/5: 0.06s\n",
      "[read ] DuckDB (file table) run 2/5: 0.07s\n",
      "[read ] DuckDB (file table) run 3/5: 0.07s\n",
      "[read ] DuckDB (file table) run 4/5: 0.07s\n",
      "[read ] DuckDB (file table) run 5/5: 0.07s\n",
      "[rnd  ] DuckDB (file table) run 1/5: 0.03s\n",
      "[rnd  ] DuckDB (file table) run 2/5: 0.02s\n",
      "[rnd  ] DuckDB (file table) run 3/5: 0.03s\n",
      "[rnd  ] DuckDB (file table) run 4/5: 0.03s\n",
      "[rnd  ] DuckDB (file table) run 5/5: 0.02s\n",
      "[format end] DuckDB (file table)\n",
      "[format start] OME-Zarr (dir-per-image)\n",
      "[write] OME-Zarr (dir-per-image) run 1/5: 8.94s\n",
      "[write] OME-Zarr (dir-per-image) run 2/5: 8.16s\n",
      "[write] OME-Zarr (dir-per-image) run 3/5: 8.30s\n",
      "[write] OME-Zarr (dir-per-image) run 4/5: 7.82s\n",
      "[write] OME-Zarr (dir-per-image) run 5/5: 10.16s\n",
      "[read ] OME-Zarr (dir-per-image) run 1/5: 12.58s\n",
      "[read ] OME-Zarr (dir-per-image) run 2/5: 6.13s\n",
      "[read ] OME-Zarr (dir-per-image) run 3/5: 5.92s\n",
      "[read ] OME-Zarr (dir-per-image) run 4/5: 5.82s\n",
      "[read ] OME-Zarr (dir-per-image) run 5/5: 5.67s\n",
      "[rnd  ] OME-Zarr (dir-per-image) run 1/5: 0.08s\n",
      "[rnd  ] OME-Zarr (dir-per-image) run 2/5: 0.06s\n",
      "[rnd  ] OME-Zarr (dir-per-image) run 3/5: 0.10s\n",
      "[rnd  ] OME-Zarr (dir-per-image) run 4/5: 0.05s\n",
      "[rnd  ] OME-Zarr (dir-per-image) run 5/5: 0.07s\n",
      "[format end] OME-Zarr (dir-per-image)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format</th>\n",
       "      <th>write_avg_s</th>\n",
       "      <th>write_std_s</th>\n",
       "      <th>read_all_avg_s</th>\n",
       "      <th>read_all_std_s</th>\n",
       "      <th>read_random_avg_s</th>\n",
       "      <th>read_random_std_s</th>\n",
       "      <th>size_mb</th>\n",
       "      <th>version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Parquet (pyarrow, zstd)</td>\n",
       "      <td>0.1021</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0538</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0471</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>9.5794</td>\n",
       "      <td>pyarrow 22.0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parquet (duckdb, zstd)</td>\n",
       "      <td>0.2348</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.1939</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>0.1399</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>9.7842</td>\n",
       "      <td>duckdb 1.4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lance (lancedb)</td>\n",
       "      <td>0.0518</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>76.4617</td>\n",
       "      <td>lancedb 0.25.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vortex</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0256</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>9.5635</td>\n",
       "      <td>vortex 0.56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DuckDB (file table)</td>\n",
       "      <td>0.1869</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0672</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0256</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>10.0117</td>\n",
       "      <td>duckdb 1.4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>OME-Zarr (dir-per-image)</td>\n",
       "      <td>8.6766</td>\n",
       "      <td>0.8247</td>\n",
       "      <td>7.2243</td>\n",
       "      <td>2.6806</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>11.4326</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     format  write_avg_s  write_std_s  read_all_avg_s  \\\n",
       "0   Parquet (pyarrow, zstd)       0.1021       0.0095          0.0538   \n",
       "1    Parquet (duckdb, zstd)       0.2348       0.0140          0.1939   \n",
       "2           Lance (lancedb)       0.0518       0.0225          0.0282   \n",
       "3                    Vortex       0.0656       0.0060          0.0131   \n",
       "4       DuckDB (file table)       0.1869       0.0081          0.0672   \n",
       "5  OME-Zarr (dir-per-image)       8.6766       0.8247          7.2243   \n",
       "\n",
       "   read_all_std_s  read_random_avg_s  read_random_std_s  size_mb  \\\n",
       "0          0.0045             0.0471             0.0046   9.5794   \n",
       "1          0.0108             0.1399             0.0013   9.7842   \n",
       "2          0.0172             0.0199             0.0011  76.4617   \n",
       "3          0.0014             0.0256             0.0013   9.5635   \n",
       "4          0.0029             0.0256             0.0020  10.0117   \n",
       "5          2.6806             0.0726             0.0144  11.4326   \n",
       "\n",
       "          version  \n",
       "0  pyarrow 22.0.0  \n",
       "1    duckdb 1.4.2  \n",
       "2  lancedb 0.25.3  \n",
       "3   vortex 0.56.0  \n",
       "4    duckdb 1.4.2  \n",
       "5                  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = run_benchmarks(table, format_configs, repeats=REPEATS)\n",
    "results_df = pd.DataFrame({\n",
    "    'format': [r['format'] for r in results],\n",
    "    'write_avg_s': [np.mean(r['write_seconds']) for r in results],\n",
    "    'write_std_s': [np.std(r['write_seconds']) for r in results],\n",
    "    'read_all_avg_s': [np.mean(r['read_seconds']) for r in results],\n",
    "    'read_all_std_s': [np.std(r['read_seconds']) for r in results],\n",
    "        'read_random_avg_s': [np.mean(r['random_read_seconds']) for r in results],\n",
    "        'read_random_std_s': [np.std(r['random_read_seconds']) for r in results],\n",
    "        'size_mb': [r['size_mb'] for r in results],\n",
    "        'version': [r.get('version', FORMAT_VERSIONS.get(r['format'], '')) for r in results],\n",
    "})\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b93eaf07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>format</th>\n",
       "      <th>kind</th>\n",
       "      <th>run</th>\n",
       "      <th>seconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Parquet (pyarrow, zstd)</td>\n",
       "      <td>write</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parquet (pyarrow, zstd)</td>\n",
       "      <td>write</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Parquet (pyarrow, zstd)</td>\n",
       "      <td>write</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parquet (pyarrow, zstd)</td>\n",
       "      <td>write</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Parquet (pyarrow, zstd)</td>\n",
       "      <td>write</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>OME-Zarr (dir-per-image)</td>\n",
       "      <td>random_read</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>OME-Zarr (dir-per-image)</td>\n",
       "      <td>random_read</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>OME-Zarr (dir-per-image)</td>\n",
       "      <td>random_read</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>OME-Zarr (dir-per-image)</td>\n",
       "      <td>random_read</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>OME-Zarr (dir-per-image)</td>\n",
       "      <td>random_read</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      format         kind  run  seconds\n",
       "0    Parquet (pyarrow, zstd)        write    0   0.1205\n",
       "1    Parquet (pyarrow, zstd)        write    1   0.0985\n",
       "2    Parquet (pyarrow, zstd)        write    2   0.1011\n",
       "3    Parquet (pyarrow, zstd)        write    3   0.0966\n",
       "4    Parquet (pyarrow, zstd)        write    4   0.0941\n",
       "..                       ...          ...  ...      ...\n",
       "85  OME-Zarr (dir-per-image)  random_read    0   0.0818\n",
       "86  OME-Zarr (dir-per-image)  random_read    1   0.0648\n",
       "87  OME-Zarr (dir-per-image)  random_read    2   0.0955\n",
       "88  OME-Zarr (dir-per-image)  random_read    3   0.0544\n",
       "89  OME-Zarr (dir-per-image)  random_read    4   0.0668\n",
       "\n",
       "[90 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timings = []\n",
    "for r in results:\n",
    "    for idx, t in enumerate(r['write_seconds']):\n",
    "        timings.append({'format': r['format'], 'kind': 'write', 'run': idx, 'seconds': t})\n",
    "    for idx, t in enumerate(r['read_seconds']):\n",
    "        timings.append({'format': r['format'], 'kind': 'read', 'run': idx, 'seconds': t})\n",
    "    for idx, t in enumerate(r['random_read_seconds']):\n",
    "        timings.append({'format': r['format'], 'kind': 'random_read', 'run': idx, 'seconds': t})\n",
    "\n",
    "pd.DataFrame(timings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
